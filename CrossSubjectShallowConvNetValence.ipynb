{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CrossSubjectShallowConvNetValence.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM9bbMrQWXNd2guAApXd9Z+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ChkvMTeqP1_v"},"source":["from scipy.stats import zscore\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n","from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import SpatialDropout2D\n","from tensorflow.keras.regularizers import l1_l2\n","from tensorflow.keras.layers import Input, Flatten\n","from tensorflow.keras.constraints import max_norm\n","from tensorflow.keras import backend as K\n","\n","from tensorflow.keras import utils as np_utils\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import balanced_accuracy_score\n","from sklearn.metrics import average_precision_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from scipy.fft import fft\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MdgM09YJhq_T"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"loLN5PPXQ4gn","executionInfo":{"status":"ok","timestamp":1630826612511,"user_tz":-270,"elapsed":20,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"cfbccc43-b9aa-4fcf-be7f-c10046638c5b"},"source":["%cd drive/MyDrive/project"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/project\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1vPdKWO_RChI","executionInfo":{"status":"ok","timestamp":1630826772279,"user_tz":-270,"elapsed":159781,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"cac90f72-5f06-49b1-b7d8-1fbb267e371c"},"source":["L=8064\n","Fs=128\n","Features=np.zeros((25600,32,3*128))\n","Labels=list()\n","for subject_id in range(0,32):\n","    if subject_id % 10 ==0:\n","      print(subject_id)\n","    loaded_data=None\n","    file_name=None\n","    if subject_id<9:\n","        file_name= 'data_preprocessed_python/s0'+str(subject_id+1)+'.dat'\n","    else:\n","        file_name= 'data_preprocessed_python/s'+str(subject_id+1)+'.dat'\n","    with open(file_name, 'rb') as f:\n","        u = pickle._Unpickler(f)\n","        u.encoding = 'latin1'\n","        loaded_data = u.load()\n","    data=loaded_data['data']\n","    Labels.append(loaded_data['labels'])\n","    \n","    for i in range(len(data)):\n","        for k in range(3,61,3):\n","          for j in range(32):   \n","            x=np.array(data[i][j][k*128:(k+3)*128]) -np.array((data[i][j][:3*128]))\n","            x=zscore(x)\n","            Features[subject_id*800+i*20+int(k/3-1)][j]=x"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","10\n","20\n","30\n"]}]},{"cell_type":"code","metadata":{"id":"8fgZ9IR7RR88"},"source":["def square(x):\n","    return K.square(x)\n","\n","def log(x):\n","    return K.log(K.clip(x, min_value = 1e-7, max_value = 10000))   \n","\n","def ShallowConvNet(nb_classes, Chans = 64, Samples = 128, dropoutRate = 0.5):\n","    input_main   = Input((Chans, Samples, 1))\n","    block1       = Conv2D(40, (1, 13), \n","                                 input_shape=(Chans, Samples, 1),\n","                                 kernel_constraint = max_norm(2., axis=(0,1,2)))(input_main)\n","    block1       = Conv2D(40, (Chans, 1), use_bias=False, \n","                          kernel_constraint = max_norm(2., axis=(0,1,2)))(block1)\n","    block1       = BatchNormalization(epsilon=1e-05, momentum=0.1)(block1)\n","    block1       = Activation(square)(block1)\n","    block1       = AveragePooling2D(pool_size=(1, 35), strides=(1, 7))(block1)\n","    block1       = Activation(log)(block1)\n","    block1       = Dropout(dropoutRate)(block1)\n","    flatten      = Flatten()(block1)\n","    dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5))(flatten)\n","    softmax      = Activation('softmax')(dense)\n","    \n","    return Model(inputs=input_main, outputs=softmax)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hxio5TnTSQ34"},"source":["y=np.zeros(800*32)\n","for j in range(32):\n","  for i in range(40):\n","    if Labels[j][i][0]>5:\n","      y[j*800+i*20:j*800+(i+1)*20]=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YLi-k9ltZnbt"},"source":["def run(train_index,test_index,\n","        dropout_rate=0.5):\n","\n","\n","\n","  Y=np_utils.to_categorical(y)\n","\n","  d_size, chans, samples = Features.shape\n","  \n","  model=ShallowConvNet(nb_classes = 2, Chans = chans, Samples = samples, \n","               dropoutRate = dropout_rate)\n","\n","  # compile the model and set the optimizers\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', \n","                metrics = ['accuracy'])\n","  \n","  # count number of parameters in the model\n","  checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1,\n","                                save_best_only=True)\n","  \n","  \n","  class_weights = {0:np.sum(y)/(len(y)-np.sum(y)), 1:1}\n","  \n","  fittedModel = model.fit(Features[train_index], Y[train_index], batch_size = 64, epochs =30 , \n","                          verbose=2, validation_data=(Features[test_index], Y[test_index]),\n","                          callbacks=[checkpointer],class_weight=class_weights)\n","  probs       = model.predict(Features[test_index])\n","  preds       = probs.argmax(axis = -1)\n","  test = Y[test_index].argmax(axis=-1)\n","  acc = accuracy_score(test, preds)\n","  cm = confusion_matrix(test, preds)\n","  f1= f1_score(test, preds)\n","  return test, preds, acc,f1 , cm, model\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aVjrLOw8TMWa"},"source":["kf=KFold(n_splits=5,shuffle=True,random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xo1ZyTXTrb7C"},"source":["train_index=list(kf.split(Features))[0][0]\n","test_index=list(kf.split(Features))[0][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6lwfyqg4rb9y","executionInfo":{"status":"ok","timestamp":1630824742601,"user_tz":-270,"elapsed":556769,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"2bd3088f-0850-4247-f26f-b7969fd7bf2b"},"source":["resuslt=run(train_index,test_index)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","320/320 - 47s - loss: 0.7275 - accuracy: 0.6348 - val_loss: 0.5304 - val_accuracy: 0.7451\n","\n","Epoch 00001: val_loss improved from inf to 0.53040, saving model to /tmp/checkpoint.h5\n","Epoch 2/30\n","320/320 - 17s - loss: 0.5545 - accuracy: 0.7650 - val_loss: 0.4535 - val_accuracy: 0.7980\n","\n","Epoch 00002: val_loss improved from 0.53040 to 0.45353, saving model to /tmp/checkpoint.h5\n","Epoch 3/30\n","320/320 - 17s - loss: 0.4757 - accuracy: 0.8103 - val_loss: 0.3918 - val_accuracy: 0.8420\n","\n","Epoch 00003: val_loss improved from 0.45353 to 0.39176, saving model to /tmp/checkpoint.h5\n","Epoch 4/30\n","320/320 - 17s - loss: 0.4294 - accuracy: 0.8372 - val_loss: 0.3690 - val_accuracy: 0.8596\n","\n","Epoch 00004: val_loss improved from 0.39176 to 0.36898, saving model to /tmp/checkpoint.h5\n","Epoch 5/30\n","320/320 - 17s - loss: 0.4027 - accuracy: 0.8561 - val_loss: 0.3470 - val_accuracy: 0.8711\n","\n","Epoch 00005: val_loss improved from 0.36898 to 0.34703, saving model to /tmp/checkpoint.h5\n","Epoch 6/30\n","320/320 - 17s - loss: 0.3819 - accuracy: 0.8695 - val_loss: 0.3438 - val_accuracy: 0.8746\n","\n","Epoch 00006: val_loss improved from 0.34703 to 0.34384, saving model to /tmp/checkpoint.h5\n","Epoch 7/30\n","320/320 - 17s - loss: 0.3729 - accuracy: 0.8726 - val_loss: 0.3340 - val_accuracy: 0.8783\n","\n","Epoch 00007: val_loss improved from 0.34384 to 0.33400, saving model to /tmp/checkpoint.h5\n","Epoch 8/30\n","320/320 - 17s - loss: 0.3646 - accuracy: 0.8785 - val_loss: 0.3399 - val_accuracy: 0.8756\n","\n","Epoch 00008: val_loss did not improve from 0.33400\n","Epoch 9/30\n","320/320 - 17s - loss: 0.3508 - accuracy: 0.8858 - val_loss: 0.3246 - val_accuracy: 0.8881\n","\n","Epoch 00009: val_loss improved from 0.33400 to 0.32461, saving model to /tmp/checkpoint.h5\n","Epoch 10/30\n","320/320 - 17s - loss: 0.3483 - accuracy: 0.8869 - val_loss: 0.3217 - val_accuracy: 0.8957\n","\n","Epoch 00010: val_loss improved from 0.32461 to 0.32172, saving model to /tmp/checkpoint.h5\n","Epoch 11/30\n","320/320 - 17s - loss: 0.3389 - accuracy: 0.8936 - val_loss: 0.3105 - val_accuracy: 0.9043\n","\n","Epoch 00011: val_loss improved from 0.32172 to 0.31054, saving model to /tmp/checkpoint.h5\n","Epoch 12/30\n","320/320 - 17s - loss: 0.3411 - accuracy: 0.8898 - val_loss: 0.3157 - val_accuracy: 0.8957\n","\n","Epoch 00012: val_loss did not improve from 0.31054\n","Epoch 13/30\n","320/320 - 17s - loss: 0.3391 - accuracy: 0.8936 - val_loss: 0.3081 - val_accuracy: 0.9021\n","\n","Epoch 00013: val_loss improved from 0.31054 to 0.30814, saving model to /tmp/checkpoint.h5\n","Epoch 14/30\n","320/320 - 17s - loss: 0.3281 - accuracy: 0.8998 - val_loss: 0.3094 - val_accuracy: 0.8971\n","\n","Epoch 00014: val_loss did not improve from 0.30814\n","Epoch 15/30\n","320/320 - 17s - loss: 0.3294 - accuracy: 0.8986 - val_loss: 0.3065 - val_accuracy: 0.9002\n","\n","Epoch 00015: val_loss improved from 0.30814 to 0.30654, saving model to /tmp/checkpoint.h5\n","Epoch 16/30\n","320/320 - 17s - loss: 0.3248 - accuracy: 0.8981 - val_loss: 0.3061 - val_accuracy: 0.9000\n","\n","Epoch 00016: val_loss improved from 0.30654 to 0.30610, saving model to /tmp/checkpoint.h5\n","Epoch 17/30\n","320/320 - 17s - loss: 0.3218 - accuracy: 0.9024 - val_loss: 0.3047 - val_accuracy: 0.9045\n","\n","Epoch 00017: val_loss improved from 0.30610 to 0.30471, saving model to /tmp/checkpoint.h5\n","Epoch 18/30\n","320/320 - 17s - loss: 0.3226 - accuracy: 0.9019 - val_loss: 0.3122 - val_accuracy: 0.8949\n","\n","Epoch 00018: val_loss did not improve from 0.30471\n","Epoch 19/30\n","320/320 - 17s - loss: 0.3261 - accuracy: 0.8973 - val_loss: 0.3145 - val_accuracy: 0.8816\n","\n","Epoch 00019: val_loss did not improve from 0.30471\n","Epoch 20/30\n","320/320 - 17s - loss: 0.3202 - accuracy: 0.9034 - val_loss: 0.2990 - val_accuracy: 0.9072\n","\n","Epoch 00020: val_loss improved from 0.30471 to 0.29904, saving model to /tmp/checkpoint.h5\n","Epoch 21/30\n","320/320 - 17s - loss: 0.3159 - accuracy: 0.9054 - val_loss: 0.3172 - val_accuracy: 0.8828\n","\n","Epoch 00021: val_loss did not improve from 0.29904\n","Epoch 22/30\n","320/320 - 17s - loss: 0.3132 - accuracy: 0.9073 - val_loss: 0.2872 - val_accuracy: 0.9100\n","\n","Epoch 00022: val_loss improved from 0.29904 to 0.28723, saving model to /tmp/checkpoint.h5\n","Epoch 23/30\n","320/320 - 17s - loss: 0.3179 - accuracy: 0.9041 - val_loss: 0.3017 - val_accuracy: 0.8951\n","\n","Epoch 00023: val_loss did not improve from 0.28723\n","Epoch 24/30\n","320/320 - 17s - loss: 0.3100 - accuracy: 0.9091 - val_loss: 0.2865 - val_accuracy: 0.9090\n","\n","Epoch 00024: val_loss improved from 0.28723 to 0.28648, saving model to /tmp/checkpoint.h5\n","Epoch 25/30\n","320/320 - 17s - loss: 0.3105 - accuracy: 0.9062 - val_loss: 0.2907 - val_accuracy: 0.9082\n","\n","Epoch 00025: val_loss did not improve from 0.28648\n","Epoch 26/30\n","320/320 - 17s - loss: 0.3050 - accuracy: 0.9120 - val_loss: 0.2873 - val_accuracy: 0.9092\n","\n","Epoch 00026: val_loss did not improve from 0.28648\n","Epoch 27/30\n","320/320 - 17s - loss: 0.3039 - accuracy: 0.9110 - val_loss: 0.2921 - val_accuracy: 0.9004\n","\n","Epoch 00027: val_loss did not improve from 0.28648\n","Epoch 28/30\n","320/320 - 17s - loss: 0.3080 - accuracy: 0.9080 - val_loss: 0.2917 - val_accuracy: 0.9127\n","\n","Epoch 00028: val_loss did not improve from 0.28648\n","Epoch 29/30\n","320/320 - 17s - loss: 0.3104 - accuracy: 0.9102 - val_loss: 0.2960 - val_accuracy: 0.9031\n","\n","Epoch 00029: val_loss did not improve from 0.28648\n","Epoch 30/30\n","320/320 - 17s - loss: 0.3037 - accuracy: 0.9109 - val_loss: 0.2967 - val_accuracy: 0.9062\n","\n","Epoch 00030: val_loss did not improve from 0.28648\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2VZFxLarcC9","executionInfo":{"status":"ok","timestamp":1630824771063,"user_tz":-270,"elapsed":565,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"475d44c4-30c0-4e16-dd9d-0b8c5017fc39"},"source":["resuslt"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1, 1, 1, ..., 1, 1, 1]),\n"," array([1, 0, 1, ..., 0, 1, 0]),\n"," 0.90625,\n"," 0.9150743099787686,\n"," array([[2054,  162],\n","        [ 318, 2586]]),\n"," <keras.engine.functional.Functional at 0x7f53f07a4b10>)"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"LW_5JktLnevn"},"source":["train_index=list(kf.split(Features))[1][0]\n","test_index=list(kf.split(Features))[1][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fk5ZMfL7v8mL","executionInfo":{"status":"ok","timestamp":1630825669234,"user_tz":-270,"elapsed":569050,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"585399e8-156f-4622-f089-d2f185aa2d49"},"source":["resuslt=run(train_index,test_index)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","320/320 - 18s - loss: 0.7327 - accuracy: 0.6321 - val_loss: 0.5393 - val_accuracy: 0.7301\n","\n","Epoch 00001: val_loss improved from inf to 0.53927, saving model to /tmp/checkpoint.h5\n","Epoch 2/30\n","320/320 - 17s - loss: 0.5537 - accuracy: 0.7634 - val_loss: 0.4467 - val_accuracy: 0.8105\n","\n","Epoch 00002: val_loss improved from 0.53927 to 0.44670, saving model to /tmp/checkpoint.h5\n","Epoch 3/30\n","320/320 - 17s - loss: 0.4702 - accuracy: 0.8123 - val_loss: 0.4302 - val_accuracy: 0.8076\n","\n","Epoch 00003: val_loss improved from 0.44670 to 0.43016, saving model to /tmp/checkpoint.h5\n","Epoch 4/30\n","320/320 - 17s - loss: 0.4292 - accuracy: 0.8410 - val_loss: 0.3822 - val_accuracy: 0.8459\n","\n","Epoch 00004: val_loss improved from 0.43016 to 0.38218, saving model to /tmp/checkpoint.h5\n","Epoch 5/30\n","320/320 - 17s - loss: 0.4085 - accuracy: 0.8517 - val_loss: 0.3581 - val_accuracy: 0.8705\n","\n","Epoch 00005: val_loss improved from 0.38218 to 0.35814, saving model to /tmp/checkpoint.h5\n","Epoch 6/30\n","320/320 - 17s - loss: 0.3844 - accuracy: 0.8687 - val_loss: 0.3606 - val_accuracy: 0.8553\n","\n","Epoch 00006: val_loss did not improve from 0.35814\n","Epoch 7/30\n","320/320 - 17s - loss: 0.3697 - accuracy: 0.8742 - val_loss: 0.3329 - val_accuracy: 0.8855\n","\n","Epoch 00007: val_loss improved from 0.35814 to 0.33288, saving model to /tmp/checkpoint.h5\n","Epoch 8/30\n","320/320 - 17s - loss: 0.3577 - accuracy: 0.8829 - val_loss: 0.3498 - val_accuracy: 0.8686\n","\n","Epoch 00008: val_loss did not improve from 0.33288\n","Epoch 9/30\n","320/320 - 17s - loss: 0.3541 - accuracy: 0.8833 - val_loss: 0.3130 - val_accuracy: 0.9020\n","\n","Epoch 00009: val_loss improved from 0.33288 to 0.31300, saving model to /tmp/checkpoint.h5\n","Epoch 10/30\n","320/320 - 17s - loss: 0.3470 - accuracy: 0.8870 - val_loss: 0.3166 - val_accuracy: 0.8939\n","\n","Epoch 00010: val_loss did not improve from 0.31300\n","Epoch 11/30\n","320/320 - 17s - loss: 0.3404 - accuracy: 0.8885 - val_loss: 0.3118 - val_accuracy: 0.8916\n","\n","Epoch 00011: val_loss improved from 0.31300 to 0.31175, saving model to /tmp/checkpoint.h5\n","Epoch 12/30\n","320/320 - 17s - loss: 0.3329 - accuracy: 0.8953 - val_loss: 0.3101 - val_accuracy: 0.8957\n","\n","Epoch 00012: val_loss improved from 0.31175 to 0.31013, saving model to /tmp/checkpoint.h5\n","Epoch 13/30\n","320/320 - 17s - loss: 0.3293 - accuracy: 0.8989 - val_loss: 0.3124 - val_accuracy: 0.9002\n","\n","Epoch 00013: val_loss did not improve from 0.31013\n","Epoch 14/30\n","320/320 - 17s - loss: 0.3313 - accuracy: 0.8957 - val_loss: 0.3055 - val_accuracy: 0.9014\n","\n","Epoch 00014: val_loss improved from 0.31013 to 0.30554, saving model to /tmp/checkpoint.h5\n","Epoch 15/30\n","320/320 - 17s - loss: 0.3263 - accuracy: 0.8989 - val_loss: 0.3127 - val_accuracy: 0.8912\n","\n","Epoch 00015: val_loss did not improve from 0.30554\n","Epoch 16/30\n","320/320 - 17s - loss: 0.3237 - accuracy: 0.9016 - val_loss: 0.2937 - val_accuracy: 0.9082\n","\n","Epoch 00016: val_loss improved from 0.30554 to 0.29368, saving model to /tmp/checkpoint.h5\n","Epoch 17/30\n","320/320 - 17s - loss: 0.3277 - accuracy: 0.8969 - val_loss: 0.2945 - val_accuracy: 0.9078\n","\n","Epoch 00017: val_loss did not improve from 0.29368\n","Epoch 18/30\n","320/320 - 17s - loss: 0.3285 - accuracy: 0.8982 - val_loss: 0.2964 - val_accuracy: 0.9137\n","\n","Epoch 00018: val_loss did not improve from 0.29368\n","Epoch 19/30\n","320/320 - 17s - loss: 0.3205 - accuracy: 0.9021 - val_loss: 0.3099 - val_accuracy: 0.8910\n","\n","Epoch 00019: val_loss did not improve from 0.29368\n","Epoch 20/30\n","320/320 - 17s - loss: 0.3202 - accuracy: 0.9023 - val_loss: 0.3210 - val_accuracy: 0.8814\n","\n","Epoch 00020: val_loss did not improve from 0.29368\n","Epoch 21/30\n","320/320 - 17s - loss: 0.3168 - accuracy: 0.9025 - val_loss: 0.2884 - val_accuracy: 0.9082\n","\n","Epoch 00021: val_loss improved from 0.29368 to 0.28838, saving model to /tmp/checkpoint.h5\n","Epoch 22/30\n","320/320 - 17s - loss: 0.3173 - accuracy: 0.9039 - val_loss: 0.3030 - val_accuracy: 0.8973\n","\n","Epoch 00022: val_loss did not improve from 0.28838\n","Epoch 23/30\n","320/320 - 17s - loss: 0.3114 - accuracy: 0.9076 - val_loss: 0.2983 - val_accuracy: 0.8959\n","\n","Epoch 00023: val_loss did not improve from 0.28838\n","Epoch 24/30\n","320/320 - 17s - loss: 0.3106 - accuracy: 0.9081 - val_loss: 0.2920 - val_accuracy: 0.9104\n","\n","Epoch 00024: val_loss did not improve from 0.28838\n","Epoch 25/30\n","320/320 - 17s - loss: 0.3071 - accuracy: 0.9104 - val_loss: 0.2905 - val_accuracy: 0.9092\n","\n","Epoch 00025: val_loss did not improve from 0.28838\n","Epoch 26/30\n","320/320 - 17s - loss: 0.3096 - accuracy: 0.9053 - val_loss: 0.2925 - val_accuracy: 0.9055\n","\n","Epoch 00026: val_loss did not improve from 0.28838\n","Epoch 27/30\n","320/320 - 17s - loss: 0.3095 - accuracy: 0.9068 - val_loss: 0.2791 - val_accuracy: 0.9137\n","\n","Epoch 00027: val_loss improved from 0.28838 to 0.27908, saving model to /tmp/checkpoint.h5\n","Epoch 28/30\n","320/320 - 17s - loss: 0.2995 - accuracy: 0.9143 - val_loss: 0.2901 - val_accuracy: 0.9051\n","\n","Epoch 00028: val_loss did not improve from 0.27908\n","Epoch 29/30\n","320/320 - 17s - loss: 0.3076 - accuracy: 0.9081 - val_loss: 0.2881 - val_accuracy: 0.9092\n","\n","Epoch 00029: val_loss did not improve from 0.27908\n","Epoch 30/30\n","320/320 - 17s - loss: 0.3019 - accuracy: 0.9161 - val_loss: 0.2788 - val_accuracy: 0.9184\n","\n","Epoch 00030: val_loss improved from 0.27908 to 0.27883, saving model to /tmp/checkpoint.h5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfIImWcUv8sG","executionInfo":{"status":"ok","timestamp":1630825690063,"user_tz":-270,"elapsed":984,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"9bc88146-df93-4499-b290-f7c8a0a2f90b"},"source":["resuslt"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1, 1, 1, ..., 1, 1, 1]),\n"," array([0, 1, 1, ..., 1, 1, 1]),\n"," 0.918359375,\n"," 0.926096181046676,\n"," array([[2083,  224],\n","        [ 194, 2619]]),\n"," <keras.engine.functional.Functional at 0x7f53f078f210>)"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"LbrAm7wtv8yJ"},"source":["train_index=list(kf.split(Features))[2][0]\n","test_index=list(kf.split(Features))[2][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QlAu0aoGv85p","executionInfo":{"status":"ok","timestamp":1630826352534,"user_tz":-270,"elapsed":569423,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"f04dc4f6-03e2-42e1-f7f6-8f3fdef2e056"},"source":["resuslt=run(train_index,test_index)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","320/320 - 19s - loss: 0.7191 - accuracy: 0.6427 - val_loss: 0.4949 - val_accuracy: 0.7668\n","\n","Epoch 00001: val_loss improved from inf to 0.49487, saving model to /tmp/checkpoint.h5\n","Epoch 2/30\n","320/320 - 17s - loss: 0.5371 - accuracy: 0.7745 - val_loss: 0.4382 - val_accuracy: 0.8020\n","\n","Epoch 00002: val_loss improved from 0.49487 to 0.43821, saving model to /tmp/checkpoint.h5\n","Epoch 3/30\n","320/320 - 17s - loss: 0.4620 - accuracy: 0.8169 - val_loss: 0.3785 - val_accuracy: 0.8477\n","\n","Epoch 00003: val_loss improved from 0.43821 to 0.37855, saving model to /tmp/checkpoint.h5\n","Epoch 4/30\n","320/320 - 17s - loss: 0.4254 - accuracy: 0.8399 - val_loss: 0.3702 - val_accuracy: 0.8525\n","\n","Epoch 00004: val_loss improved from 0.37855 to 0.37021, saving model to /tmp/checkpoint.h5\n","Epoch 5/30\n","320/320 - 17s - loss: 0.3943 - accuracy: 0.8565 - val_loss: 0.3402 - val_accuracy: 0.8768\n","\n","Epoch 00005: val_loss improved from 0.37021 to 0.34024, saving model to /tmp/checkpoint.h5\n","Epoch 6/30\n","320/320 - 17s - loss: 0.3819 - accuracy: 0.8654 - val_loss: 0.3467 - val_accuracy: 0.8750\n","\n","Epoch 00006: val_loss did not improve from 0.34024\n","Epoch 7/30\n","320/320 - 17s - loss: 0.3653 - accuracy: 0.8771 - val_loss: 0.3597 - val_accuracy: 0.8611\n","\n","Epoch 00007: val_loss did not improve from 0.34024\n","Epoch 8/30\n","320/320 - 17s - loss: 0.3571 - accuracy: 0.8821 - val_loss: 0.3341 - val_accuracy: 0.8836\n","\n","Epoch 00008: val_loss improved from 0.34024 to 0.33408, saving model to /tmp/checkpoint.h5\n","Epoch 9/30\n","320/320 - 17s - loss: 0.3417 - accuracy: 0.8900 - val_loss: 0.3105 - val_accuracy: 0.8969\n","\n","Epoch 00009: val_loss improved from 0.33408 to 0.31045, saving model to /tmp/checkpoint.h5\n","Epoch 10/30\n","320/320 - 17s - loss: 0.3363 - accuracy: 0.8930 - val_loss: 0.3155 - val_accuracy: 0.8945\n","\n","Epoch 00010: val_loss did not improve from 0.31045\n","Epoch 11/30\n","320/320 - 17s - loss: 0.3401 - accuracy: 0.8919 - val_loss: 0.3177 - val_accuracy: 0.8910\n","\n","Epoch 00011: val_loss did not improve from 0.31045\n","Epoch 12/30\n","320/320 - 17s - loss: 0.3351 - accuracy: 0.8944 - val_loss: 0.3180 - val_accuracy: 0.8902\n","\n","Epoch 00012: val_loss did not improve from 0.31045\n","Epoch 13/30\n","320/320 - 17s - loss: 0.3333 - accuracy: 0.8925 - val_loss: 0.3060 - val_accuracy: 0.9064\n","\n","Epoch 00013: val_loss improved from 0.31045 to 0.30602, saving model to /tmp/checkpoint.h5\n","Epoch 14/30\n","320/320 - 17s - loss: 0.3272 - accuracy: 0.8965 - val_loss: 0.3313 - val_accuracy: 0.8775\n","\n","Epoch 00014: val_loss did not improve from 0.30602\n","Epoch 15/30\n","320/320 - 17s - loss: 0.3272 - accuracy: 0.8992 - val_loss: 0.2996 - val_accuracy: 0.8969\n","\n","Epoch 00015: val_loss improved from 0.30602 to 0.29961, saving model to /tmp/checkpoint.h5\n","Epoch 16/30\n","320/320 - 17s - loss: 0.3298 - accuracy: 0.8972 - val_loss: 0.3051 - val_accuracy: 0.9041\n","\n","Epoch 00016: val_loss did not improve from 0.29961\n","Epoch 17/30\n","320/320 - 17s - loss: 0.3259 - accuracy: 0.8984 - val_loss: 0.3057 - val_accuracy: 0.9016\n","\n","Epoch 00017: val_loss did not improve from 0.29961\n","Epoch 18/30\n","320/320 - 17s - loss: 0.3253 - accuracy: 0.9006 - val_loss: 0.3167 - val_accuracy: 0.8861\n","\n","Epoch 00018: val_loss did not improve from 0.29961\n","Epoch 19/30\n","320/320 - 17s - loss: 0.3203 - accuracy: 0.9003 - val_loss: 0.3090 - val_accuracy: 0.8928\n","\n","Epoch 00019: val_loss did not improve from 0.29961\n","Epoch 20/30\n","320/320 - 17s - loss: 0.3189 - accuracy: 0.9033 - val_loss: 0.3267 - val_accuracy: 0.8744\n","\n","Epoch 00020: val_loss did not improve from 0.29961\n","Epoch 21/30\n","320/320 - 17s - loss: 0.3179 - accuracy: 0.9033 - val_loss: 0.3118 - val_accuracy: 0.8975\n","\n","Epoch 00021: val_loss did not improve from 0.29961\n","Epoch 22/30\n","320/320 - 17s - loss: 0.3175 - accuracy: 0.9035 - val_loss: 0.2861 - val_accuracy: 0.9066\n","\n","Epoch 00022: val_loss improved from 0.29961 to 0.28615, saving model to /tmp/checkpoint.h5\n","Epoch 23/30\n","320/320 - 17s - loss: 0.3179 - accuracy: 0.9038 - val_loss: 0.2928 - val_accuracy: 0.9072\n","\n","Epoch 00023: val_loss did not improve from 0.28615\n","Epoch 24/30\n","320/320 - 17s - loss: 0.3141 - accuracy: 0.9043 - val_loss: 0.2985 - val_accuracy: 0.9027\n","\n","Epoch 00024: val_loss did not improve from 0.28615\n","Epoch 25/30\n","320/320 - 17s - loss: 0.3112 - accuracy: 0.9052 - val_loss: 0.2833 - val_accuracy: 0.9154\n","\n","Epoch 00025: val_loss improved from 0.28615 to 0.28334, saving model to /tmp/checkpoint.h5\n","Epoch 26/30\n","320/320 - 17s - loss: 0.3118 - accuracy: 0.9090 - val_loss: 0.2958 - val_accuracy: 0.9029\n","\n","Epoch 00026: val_loss did not improve from 0.28334\n","Epoch 27/30\n","320/320 - 17s - loss: 0.3064 - accuracy: 0.9077 - val_loss: 0.2902 - val_accuracy: 0.9086\n","\n","Epoch 00027: val_loss did not improve from 0.28334\n","Epoch 28/30\n","320/320 - 17s - loss: 0.3063 - accuracy: 0.9097 - val_loss: 0.3052 - val_accuracy: 0.9023\n","\n","Epoch 00028: val_loss did not improve from 0.28334\n","Epoch 29/30\n","320/320 - 17s - loss: 0.3031 - accuracy: 0.9123 - val_loss: 0.2921 - val_accuracy: 0.9010\n","\n","Epoch 00029: val_loss did not improve from 0.28334\n","Epoch 30/30\n","320/320 - 17s - loss: 0.3036 - accuracy: 0.9108 - val_loss: 0.2868 - val_accuracy: 0.9094\n","\n","Epoch 00030: val_loss did not improve from 0.28334\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3cgAyh-yd8X","executionInfo":{"status":"ok","timestamp":1630826555574,"user_tz":-270,"elapsed":935,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"6b188a88-c798-40b6-f09b-db5fe387297f"},"source":["resuslt"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1, 1, 1, ..., 0, 1, 1]),\n"," array([1, 1, 1, ..., 0, 1, 1]),\n"," 0.909375,\n"," 0.9177013125221708,\n"," array([[2069,  206],\n","        [ 258, 2587]]),\n"," <keras.engine.functional.Functional at 0x7f53f07d9610>)"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"LwfZ5uzOyeCD"},"source":["train_index=list(kf.split(Features))[3][0]\n","test_index=list(kf.split(Features))[3][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RItMn_Ln1nN_","executionInfo":{"status":"ok","timestamp":1630827349615,"user_tz":-270,"elapsed":577341,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"bdce4a1b-83b5-4d32-bcd6-ea94c677be0b"},"source":["resuslt=run(train_index,test_index)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 00001: val_loss improved from inf to 0.54177, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00002: val_loss improved from 0.54177 to 0.46781, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00003: val_loss improved from 0.46781 to 0.39406, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00004: val_loss improved from 0.39406 to 0.36722, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00005: val_loss improved from 0.36722 to 0.35804, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00006: val_loss improved from 0.35804 to 0.33746, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00007: val_loss did not improve from 0.33746\n","\n","Epoch 00008: val_loss improved from 0.33746 to 0.33484, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00009: val_loss did not improve from 0.33484\n","\n","Epoch 00010: val_loss improved from 0.33484 to 0.31025, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00011: val_loss did not improve from 0.31025\n","\n","Epoch 00012: val_loss did not improve from 0.31025\n","\n","Epoch 00013: val_loss did not improve from 0.31025\n","\n","Epoch 00014: val_loss improved from 0.31025 to 0.29970, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00015: val_loss did not improve from 0.29970\n","\n","Epoch 00016: val_loss did not improve from 0.29970\n","\n","Epoch 00017: val_loss improved from 0.29970 to 0.29149, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00018: val_loss did not improve from 0.29149\n","\n","Epoch 00019: val_loss did not improve from 0.29149\n","\n","Epoch 00020: val_loss did not improve from 0.29149\n","\n","Epoch 00021: val_loss did not improve from 0.29149\n","\n","Epoch 00022: val_loss did not improve from 0.29149\n","\n","Epoch 00023: val_loss improved from 0.29149 to 0.28888, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00024: val_loss did not improve from 0.28888\n","\n","Epoch 00025: val_loss improved from 0.28888 to 0.28074, saving model to /tmp/checkpoint.h5\n","\n","Epoch 00026: val_loss did not improve from 0.28074\n","\n","Epoch 00027: val_loss did not improve from 0.28074\n","\n","Epoch 00028: val_loss did not improve from 0.28074\n","\n","Epoch 00029: val_loss did not improve from 0.28074\n","\n","Epoch 00030: val_loss did not improve from 0.28074\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UG0Xgjp81nQi","executionInfo":{"status":"ok","timestamp":1630827418592,"user_tz":-270,"elapsed":803,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"16734559-54b9-4676-c2ae-2038b86f3d20"},"source":["resuslt"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1, 1, 1, ..., 1, 1, 1]),\n"," array([1, 1, 1, ..., 1, 1, 1]),\n"," 0.8908203125,\n"," 0.9026302037972479,\n"," array([[1970,  328],\n","        [ 231, 2591]]),\n"," <keras.engine.functional.Functional at 0x7fd52015fa50>)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"qiAY6Tx15pBk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DI8hnQGX5pD8"},"source":["train_index=list(kf.split(Features))[4][0]\n","test_index=list(kf.split(Features))[4][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9e0CkNha5pGj","executionInfo":{"status":"ok","timestamp":1630828207992,"user_tz":-270,"elapsed":568143,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"b2949653-4755-4287-a0c4-e044f9bf40a9"},"source":["resuslt=run(train_index,test_index)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","320/320 - 18s - loss: 0.7255 - accuracy: 0.6368 - val_loss: 0.5378 - val_accuracy: 0.7281\n","\n","Epoch 00001: val_loss improved from inf to 0.53782, saving model to /tmp/checkpoint.h5\n","Epoch 2/30\n","320/320 - 17s - loss: 0.5624 - accuracy: 0.7561 - val_loss: 0.4483 - val_accuracy: 0.8002\n","\n","Epoch 00002: val_loss improved from 0.53782 to 0.44832, saving model to /tmp/checkpoint.h5\n","Epoch 3/30\n","320/320 - 17s - loss: 0.4745 - accuracy: 0.8153 - val_loss: 0.3856 - val_accuracy: 0.8504\n","\n","Epoch 00003: val_loss improved from 0.44832 to 0.38563, saving model to /tmp/checkpoint.h5\n","Epoch 4/30\n","320/320 - 17s - loss: 0.4293 - accuracy: 0.8396 - val_loss: 0.3809 - val_accuracy: 0.8596\n","\n","Epoch 00004: val_loss improved from 0.38563 to 0.38087, saving model to /tmp/checkpoint.h5\n","Epoch 5/30\n","320/320 - 17s - loss: 0.4106 - accuracy: 0.8501 - val_loss: 0.3573 - val_accuracy: 0.8689\n","\n","Epoch 00005: val_loss improved from 0.38087 to 0.35728, saving model to /tmp/checkpoint.h5\n","Epoch 6/30\n","320/320 - 17s - loss: 0.3905 - accuracy: 0.8652 - val_loss: 0.3434 - val_accuracy: 0.8719\n","\n","Epoch 00006: val_loss improved from 0.35728 to 0.34342, saving model to /tmp/checkpoint.h5\n","Epoch 7/30\n","320/320 - 17s - loss: 0.3678 - accuracy: 0.8764 - val_loss: 0.3339 - val_accuracy: 0.8750\n","\n","Epoch 00007: val_loss improved from 0.34342 to 0.33386, saving model to /tmp/checkpoint.h5\n","Epoch 8/30\n","320/320 - 17s - loss: 0.3687 - accuracy: 0.8742 - val_loss: 0.3289 - val_accuracy: 0.8795\n","\n","Epoch 00008: val_loss improved from 0.33386 to 0.32885, saving model to /tmp/checkpoint.h5\n","Epoch 9/30\n","320/320 - 17s - loss: 0.3589 - accuracy: 0.8781 - val_loss: 0.3327 - val_accuracy: 0.8766\n","\n","Epoch 00009: val_loss did not improve from 0.32885\n","Epoch 10/30\n","320/320 - 17s - loss: 0.3474 - accuracy: 0.8898 - val_loss: 0.3104 - val_accuracy: 0.8951\n","\n","Epoch 00010: val_loss improved from 0.32885 to 0.31035, saving model to /tmp/checkpoint.h5\n","Epoch 11/30\n","320/320 - 17s - loss: 0.3421 - accuracy: 0.8917 - val_loss: 0.3358 - val_accuracy: 0.8789\n","\n","Epoch 00011: val_loss did not improve from 0.31035\n","Epoch 12/30\n","320/320 - 17s - loss: 0.3402 - accuracy: 0.8907 - val_loss: 0.3235 - val_accuracy: 0.8877\n","\n","Epoch 00012: val_loss did not improve from 0.31035\n","Epoch 13/30\n","320/320 - 17s - loss: 0.3411 - accuracy: 0.8900 - val_loss: 0.3121 - val_accuracy: 0.8961\n","\n","Epoch 00013: val_loss did not improve from 0.31035\n","Epoch 14/30\n","320/320 - 17s - loss: 0.3352 - accuracy: 0.8931 - val_loss: 0.3077 - val_accuracy: 0.9014\n","\n","Epoch 00014: val_loss improved from 0.31035 to 0.30767, saving model to /tmp/checkpoint.h5\n","Epoch 15/30\n","320/320 - 17s - loss: 0.3346 - accuracy: 0.8942 - val_loss: 0.2990 - val_accuracy: 0.9061\n","\n","Epoch 00015: val_loss improved from 0.30767 to 0.29897, saving model to /tmp/checkpoint.h5\n","Epoch 16/30\n","320/320 - 17s - loss: 0.3302 - accuracy: 0.8979 - val_loss: 0.2993 - val_accuracy: 0.9107\n","\n","Epoch 00016: val_loss did not improve from 0.29897\n","Epoch 17/30\n","320/320 - 17s - loss: 0.3272 - accuracy: 0.8971 - val_loss: 0.3037 - val_accuracy: 0.9025\n","\n","Epoch 00017: val_loss did not improve from 0.29897\n","Epoch 18/30\n","320/320 - 17s - loss: 0.3296 - accuracy: 0.8967 - val_loss: 0.2935 - val_accuracy: 0.9070\n","\n","Epoch 00018: val_loss improved from 0.29897 to 0.29353, saving model to /tmp/checkpoint.h5\n","Epoch 19/30\n","320/320 - 17s - loss: 0.3224 - accuracy: 0.9029 - val_loss: 0.2999 - val_accuracy: 0.9047\n","\n","Epoch 00019: val_loss did not improve from 0.29353\n","Epoch 20/30\n","320/320 - 17s - loss: 0.3228 - accuracy: 0.9025 - val_loss: 0.2971 - val_accuracy: 0.9047\n","\n","Epoch 00020: val_loss did not improve from 0.29353\n","Epoch 21/30\n","320/320 - 17s - loss: 0.3212 - accuracy: 0.9011 - val_loss: 0.3062 - val_accuracy: 0.8949\n","\n","Epoch 00021: val_loss did not improve from 0.29353\n","Epoch 22/30\n","320/320 - 17s - loss: 0.3186 - accuracy: 0.9024 - val_loss: 0.3050 - val_accuracy: 0.8887\n","\n","Epoch 00022: val_loss did not improve from 0.29353\n","Epoch 23/30\n","320/320 - 17s - loss: 0.3160 - accuracy: 0.9041 - val_loss: 0.2848 - val_accuracy: 0.9146\n","\n","Epoch 00023: val_loss improved from 0.29353 to 0.28479, saving model to /tmp/checkpoint.h5\n","Epoch 24/30\n","320/320 - 17s - loss: 0.3131 - accuracy: 0.9054 - val_loss: 0.2905 - val_accuracy: 0.9113\n","\n","Epoch 00024: val_loss did not improve from 0.28479\n","Epoch 25/30\n","320/320 - 18s - loss: 0.3151 - accuracy: 0.9050 - val_loss: 0.3116 - val_accuracy: 0.8941\n","\n","Epoch 00025: val_loss did not improve from 0.28479\n","Epoch 26/30\n","320/320 - 17s - loss: 0.3136 - accuracy: 0.9066 - val_loss: 0.2951 - val_accuracy: 0.9025\n","\n","Epoch 00026: val_loss did not improve from 0.28479\n","Epoch 27/30\n","320/320 - 17s - loss: 0.3085 - accuracy: 0.9078 - val_loss: 0.2919 - val_accuracy: 0.9088\n","\n","Epoch 00027: val_loss did not improve from 0.28479\n","Epoch 28/30\n","320/320 - 18s - loss: 0.3040 - accuracy: 0.9096 - val_loss: 0.2962 - val_accuracy: 0.9012\n","\n","Epoch 00028: val_loss did not improve from 0.28479\n","Epoch 29/30\n","320/320 - 17s - loss: 0.3167 - accuracy: 0.9027 - val_loss: 0.3023 - val_accuracy: 0.9018\n","\n","Epoch 00029: val_loss did not improve from 0.28479\n","Epoch 30/30\n","320/320 - 17s - loss: 0.3031 - accuracy: 0.9113 - val_loss: 0.3002 - val_accuracy: 0.8996\n","\n","Epoch 00030: val_loss did not improve from 0.28479\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JogLuZjG5uny","executionInfo":{"status":"ok","timestamp":1630828872038,"user_tz":-270,"elapsed":585,"user":{"displayName":"Mahdi Bazargani","photoUrl":"","userId":"10388230212582372567"}},"outputId":"42e251dd-a471-41dd-b9f5-023fe7f33351"},"source":["resuslt"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1, 1, 1, ..., 1, 1, 1]),\n"," array([1, 1, 1, ..., 1, 1, 1]),\n"," 0.899609375,\n"," 0.9076204169662114,\n"," array([[2081,  263],\n","        [ 251, 2525]]),\n"," <keras.engine.functional.Functional at 0x7fd48a5f6e90>)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Iaehzqk85uqI"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dITXtd5O5usp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdlMzBbDTXbi","outputId":"fa0ebe14-927c-4b12-8929-be6668d30d55"},"source":["results=[]\n","for train_index, test_index in kf.split(Features):\n","  res=run(train_index,test_index)\n","  results.append(res)\n","  print(res)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","320/320 - 18s - loss: 0.7240 - accuracy: 0.6426 - val_loss: 0.5208 - val_accuracy: 0.7592\n","\n","Epoch 00001: val_loss improved from inf to 0.52084, saving model to /tmp/checkpoint.h5\n","Epoch 2/30\n","320/320 - 17s - loss: 0.5542 - accuracy: 0.7589 - val_loss: 0.4520 - val_accuracy: 0.8010\n","\n","Epoch 00002: val_loss improved from 0.52084 to 0.45199, saving model to /tmp/checkpoint.h5\n","Epoch 3/30\n","320/320 - 17s - loss: 0.4749 - accuracy: 0.8104 - val_loss: 0.4008 - val_accuracy: 0.8449\n","\n","Epoch 00003: val_loss improved from 0.45199 to 0.40076, saving model to /tmp/checkpoint.h5\n","Epoch 4/30\n","320/320 - 17s - loss: 0.4250 - accuracy: 0.8417 - val_loss: 0.3654 - val_accuracy: 0.8625\n","\n","Epoch 00004: val_loss improved from 0.40076 to 0.36542, saving model to /tmp/checkpoint.h5\n","Epoch 5/30\n","320/320 - 16s - loss: 0.4006 - accuracy: 0.8557 - val_loss: 0.3770 - val_accuracy: 0.8490\n","\n","Epoch 00005: val_loss did not improve from 0.36542\n","Epoch 6/30\n","320/320 - 17s - loss: 0.3849 - accuracy: 0.8673 - val_loss: 0.3460 - val_accuracy: 0.8742\n","\n","Epoch 00006: val_loss improved from 0.36542 to 0.34600, saving model to /tmp/checkpoint.h5\n","Epoch 7/30\n","320/320 - 16s - loss: 0.3695 - accuracy: 0.8743 - val_loss: 0.3786 - val_accuracy: 0.8465\n","\n","Epoch 00007: val_loss did not improve from 0.34600\n","Epoch 8/30\n","320/320 - 16s - loss: 0.3610 - accuracy: 0.8785 - val_loss: 0.3288 - val_accuracy: 0.8877\n","\n","Epoch 00008: val_loss improved from 0.34600 to 0.32882, saving model to /tmp/checkpoint.h5\n","Epoch 9/30\n","320/320 - 16s - loss: 0.3495 - accuracy: 0.8893 - val_loss: 0.3177 - val_accuracy: 0.9008\n","\n","Epoch 00009: val_loss improved from 0.32882 to 0.31767, saving model to /tmp/checkpoint.h5\n","Epoch 10/30\n","320/320 - 16s - loss: 0.3455 - accuracy: 0.8890 - val_loss: 0.3117 - val_accuracy: 0.8988\n","\n","Epoch 00010: val_loss improved from 0.31767 to 0.31174, saving model to /tmp/checkpoint.h5\n","Epoch 11/30\n","320/320 - 17s - loss: 0.3369 - accuracy: 0.8957 - val_loss: 0.3192 - val_accuracy: 0.8928\n","\n","Epoch 00011: val_loss did not improve from 0.31174\n","Epoch 12/30\n","320/320 - 17s - loss: 0.3294 - accuracy: 0.8981 - val_loss: 0.3216 - val_accuracy: 0.8818\n","\n","Epoch 00012: val_loss did not improve from 0.31174\n","Epoch 13/30\n","320/320 - 17s - loss: 0.3333 - accuracy: 0.8953 - val_loss: 0.3164 - val_accuracy: 0.8941\n","\n","Epoch 00013: val_loss did not improve from 0.31174\n","Epoch 14/30\n","320/320 - 16s - loss: 0.3329 - accuracy: 0.8953 - val_loss: 0.3309 - val_accuracy: 0.8764\n","\n","Epoch 00014: val_loss did not improve from 0.31174\n","Epoch 15/30\n","320/320 - 16s - loss: 0.3314 - accuracy: 0.8934 - val_loss: 0.3074 - val_accuracy: 0.9008\n","\n","Epoch 00015: val_loss improved from 0.31174 to 0.30741, saving model to /tmp/checkpoint.h5\n","Epoch 16/30\n","320/320 - 16s - loss: 0.3223 - accuracy: 0.9017 - val_loss: 0.3114 - val_accuracy: 0.8994\n","\n","Epoch 00016: val_loss did not improve from 0.30741\n","Epoch 17/30\n","320/320 - 17s - loss: 0.3207 - accuracy: 0.9028 - val_loss: 0.3132 - val_accuracy: 0.9031\n","\n","Epoch 00017: val_loss did not improve from 0.30741\n","Epoch 18/30\n","320/320 - 16s - loss: 0.3186 - accuracy: 0.9053 - val_loss: 0.3194 - val_accuracy: 0.8832\n","\n","Epoch 00018: val_loss did not improve from 0.30741\n","Epoch 19/30\n","320/320 - 16s - loss: 0.3271 - accuracy: 0.9000 - val_loss: 0.3147 - val_accuracy: 0.8943\n","\n","Epoch 00019: val_loss did not improve from 0.30741\n","Epoch 20/30\n","320/320 - 16s - loss: 0.3170 - accuracy: 0.9021 - val_loss: 0.2956 - val_accuracy: 0.9109\n","\n","Epoch 00020: val_loss improved from 0.30741 to 0.29555, saving model to /tmp/checkpoint.h5\n","Epoch 21/30\n","320/320 - 17s - loss: 0.3145 - accuracy: 0.9064 - val_loss: 0.3267 - val_accuracy: 0.8787\n","\n","Epoch 00021: val_loss did not improve from 0.29555\n","Epoch 22/30\n","320/320 - 16s - loss: 0.3147 - accuracy: 0.9060 - val_loss: 0.3040 - val_accuracy: 0.8936\n","\n","Epoch 00022: val_loss did not improve from 0.29555\n","Epoch 23/30\n","320/320 - 16s - loss: 0.3089 - accuracy: 0.9104 - val_loss: 0.3029 - val_accuracy: 0.8986\n","\n","Epoch 00023: val_loss did not improve from 0.29555\n","Epoch 24/30\n","320/320 - 17s - loss: 0.3151 - accuracy: 0.9067 - val_loss: 0.2982 - val_accuracy: 0.9078\n","\n","Epoch 00024: val_loss did not improve from 0.29555\n","Epoch 25/30\n","320/320 - 17s - loss: 0.3101 - accuracy: 0.9062 - val_loss: 0.3043 - val_accuracy: 0.9000\n","\n","Epoch 00025: val_loss did not improve from 0.29555\n","Epoch 26/30\n","320/320 - 16s - loss: 0.3113 - accuracy: 0.9074 - val_loss: 0.2816 - val_accuracy: 0.9238\n","\n","Epoch 00026: val_loss improved from 0.29555 to 0.28162, saving model to /tmp/checkpoint.h5\n","Epoch 27/30\n","320/320 - 17s - loss: 0.3069 - accuracy: 0.9108 - val_loss: 0.3157 - val_accuracy: 0.8889\n","\n","Epoch 00027: val_loss did not improve from 0.28162\n","Epoch 28/30\n","320/320 - 16s - loss: 0.3036 - accuracy: 0.9092 - val_loss: 0.2865 - val_accuracy: 0.9150\n","\n","Epoch 00028: val_loss did not improve from 0.28162\n","Epoch 29/30\n","320/320 - 16s - loss: 0.3056 - accuracy: 0.9106 - val_loss: 0.2949 - val_accuracy: 0.9102\n","\n","Epoch 00029: val_loss did not improve from 0.28162\n","Epoch 30/30\n","320/320 - 16s - loss: 0.3047 - accuracy: 0.9112 - val_loss: 0.2980 - val_accuracy: 0.8984\n","\n","Epoch 00030: val_loss did not improve from 0.28162\n","(array([1, 1, 1, ..., 1, 1, 1]), array([1, 1, 0, ..., 0, 0, 1]), 0.8984375, 0.9079320113314449, array([[2036,  198],\n","       [ 322, 2564]]), <keras.engine.functional.Functional object at 0x7fce14883650>)\n","Epoch 1/30\n","320/320 - 18s - loss: 0.7262 - accuracy: 0.6366 - val_loss: 0.5282 - val_accuracy: 0.7340\n","\n","Epoch 00001: val_loss improved from inf to 0.52819, saving model to /tmp/checkpoint.h5\n","Epoch 2/30\n","320/320 - 17s - loss: 0.5484 - accuracy: 0.7631 - val_loss: 0.4252 - val_accuracy: 0.8195\n","\n","Epoch 00002: val_loss improved from 0.52819 to 0.42518, saving model to /tmp/checkpoint.h5\n","Epoch 3/30\n","320/320 - 16s - loss: 0.4767 - accuracy: 0.8081 - val_loss: 0.3961 - val_accuracy: 0.8432\n","\n","Epoch 00003: val_loss improved from 0.42518 to 0.39608, saving model to /tmp/checkpoint.h5\n","Epoch 4/30\n","320/320 - 17s - loss: 0.4258 - accuracy: 0.8406 - val_loss: 0.3815 - val_accuracy: 0.8461\n","\n","Epoch 00004: val_loss improved from 0.39608 to 0.38149, saving model to /tmp/checkpoint.h5\n","Epoch 5/30\n","320/320 - 17s - loss: 0.4100 - accuracy: 0.8491 - val_loss: 0.3761 - val_accuracy: 0.8453\n","\n","Epoch 00005: val_loss improved from 0.38149 to 0.37612, saving model to /tmp/checkpoint.h5\n","Epoch 6/30\n","320/320 - 16s - loss: 0.3768 - accuracy: 0.8713 - val_loss: 0.3474 - val_accuracy: 0.8785\n","\n","Epoch 00006: val_loss improved from 0.37612 to 0.34738, saving model to /tmp/checkpoint.h5\n","Epoch 7/30\n","320/320 - 17s - loss: 0.3676 - accuracy: 0.8784 - val_loss: 0.3293 - val_accuracy: 0.8979\n","\n","Epoch 00007: val_loss improved from 0.34738 to 0.32927, saving model to /tmp/checkpoint.h5\n","Epoch 8/30\n","320/320 - 17s - loss: 0.3589 - accuracy: 0.8815 - val_loss: 0.3215 - val_accuracy: 0.8941\n","\n","Epoch 00008: val_loss improved from 0.32927 to 0.32150, saving model to /tmp/checkpoint.h5\n","Epoch 9/30\n","320/320 - 17s - loss: 0.3515 - accuracy: 0.8853 - val_loss: 0.3197 - val_accuracy: 0.8953\n","\n","Epoch 00009: val_loss improved from 0.32150 to 0.31973, saving model to /tmp/checkpoint.h5\n","Epoch 10/30\n","320/320 - 16s - loss: 0.3419 - accuracy: 0.8911 - val_loss: 0.3148 - val_accuracy: 0.8900\n","\n","Epoch 00010: val_loss improved from 0.31973 to 0.31480, saving model to /tmp/checkpoint.h5\n","Epoch 11/30\n","320/320 - 16s - loss: 0.3382 - accuracy: 0.8930 - val_loss: 0.3182 - val_accuracy: 0.8900\n","\n","Epoch 00011: val_loss did not improve from 0.31480\n","Epoch 12/30\n","320/320 - 17s - loss: 0.3375 - accuracy: 0.8925 - val_loss: 0.3079 - val_accuracy: 0.8969\n","\n","Epoch 00012: val_loss improved from 0.31480 to 0.30791, saving model to /tmp/checkpoint.h5\n","Epoch 13/30\n","320/320 - 16s - loss: 0.3421 - accuracy: 0.8902 - val_loss: 0.3144 - val_accuracy: 0.8914\n","\n","Epoch 00013: val_loss did not improve from 0.30791\n","Epoch 14/30\n","320/320 - 16s - loss: 0.3303 - accuracy: 0.8964 - val_loss: 0.3067 - val_accuracy: 0.8941\n","\n","Epoch 00014: val_loss improved from 0.30791 to 0.30674, saving model to /tmp/checkpoint.h5\n","Epoch 15/30\n","320/320 - 16s - loss: 0.3324 - accuracy: 0.8948 - val_loss: 0.3009 - val_accuracy: 0.9033\n","\n","Epoch 00015: val_loss improved from 0.30674 to 0.30089, saving model to /tmp/checkpoint.h5\n","Epoch 16/30\n","320/320 - 16s - loss: 0.3249 - accuracy: 0.8965 - val_loss: 0.3218 - val_accuracy: 0.8803\n","\n","Epoch 00016: val_loss did not improve from 0.30089\n","Epoch 17/30\n","320/320 - 16s - loss: 0.3230 - accuracy: 0.8982 - val_loss: 0.3079 - val_accuracy: 0.8986\n","\n","Epoch 00017: val_loss did not improve from 0.30089\n","Epoch 18/30\n","320/320 - 16s - loss: 0.3154 - accuracy: 0.9038 - val_loss: 0.3082 - val_accuracy: 0.8969\n","\n","Epoch 00018: val_loss did not improve from 0.30089\n","Epoch 19/30\n","320/320 - 16s - loss: 0.3175 - accuracy: 0.9037 - val_loss: 0.3453 - val_accuracy: 0.8613\n","\n","Epoch 00019: val_loss did not improve from 0.30089\n","Epoch 20/30\n","320/320 - 16s - loss: 0.3153 - accuracy: 0.9051 - val_loss: 0.3005 - val_accuracy: 0.8994\n","\n","Epoch 00020: val_loss improved from 0.30089 to 0.30046, saving model to /tmp/checkpoint.h5\n","Epoch 21/30\n","320/320 - 16s - loss: 0.3153 - accuracy: 0.9065 - val_loss: 0.3034 - val_accuracy: 0.8998\n","\n","Epoch 00021: val_loss did not improve from 0.30046\n","Epoch 22/30\n","320/320 - 16s - loss: 0.3134 - accuracy: 0.9045 - val_loss: 0.2894 - val_accuracy: 0.9170\n","\n","Epoch 00022: val_loss improved from 0.30046 to 0.28939, saving model to /tmp/checkpoint.h5\n","Epoch 23/30\n","320/320 - 16s - loss: 0.3102 - accuracy: 0.9087 - val_loss: 0.2962 - val_accuracy: 0.8986\n","\n","Epoch 00023: val_loss did not improve from 0.28939\n","Epoch 24/30\n","320/320 - 16s - loss: 0.3090 - accuracy: 0.9076 - val_loss: 0.2944 - val_accuracy: 0.9045\n","\n","Epoch 00024: val_loss did not improve from 0.28939\n","Epoch 25/30\n","320/320 - 16s - loss: 0.3108 - accuracy: 0.9090 - val_loss: 0.2985 - val_accuracy: 0.8988\n","\n","Epoch 00025: val_loss did not improve from 0.28939\n","Epoch 26/30\n","320/320 - 17s - loss: 0.3018 - accuracy: 0.9104 - val_loss: 0.2917 - val_accuracy: 0.9094\n","\n","Epoch 00026: val_loss did not improve from 0.28939\n","Epoch 27/30\n","320/320 - 17s - loss: 0.3074 - accuracy: 0.9098 - val_loss: 0.3118 - val_accuracy: 0.8883\n","\n","Epoch 00027: val_loss did not improve from 0.28939\n","Epoch 28/30\n","320/320 - 17s - loss: 0.3086 - accuracy: 0.9103 - val_loss: 0.2922 - val_accuracy: 0.9123\n","\n","Epoch 00028: val_loss did not improve from 0.28939\n","Epoch 29/30\n","320/320 - 16s - loss: 0.3050 - accuracy: 0.9110 - val_loss: 0.3002 - val_accuracy: 0.8943\n","\n","Epoch 00029: val_loss did not improve from 0.28939\n","Epoch 30/30\n","320/320 - 16s - loss: 0.3028 - accuracy: 0.9106 - val_loss: 0.3018 - val_accuracy: 0.8969\n","\n","Epoch 00030: val_loss did not improve from 0.28939\n","(array([1, 1, 1, ..., 0, 1, 1]), array([1, 1, 1, ..., 0, 0, 1]), 0.896875, 0.9067137809187279, array([[2026,  262],\n","       [ 266, 2566]]), <keras.engine.functional.Functional object at 0x7fce14864410>)\n"]}]},{"cell_type":"code","metadata":{"id":"q1lkG1ybYT-z"},"source":[""],"execution_count":null,"outputs":[]}]}